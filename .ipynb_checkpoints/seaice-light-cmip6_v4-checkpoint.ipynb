{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/trondkr/anaconda3/envs/py3/lib/python3.7/site-packages/xarray/core/merge.py:17: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  PANDAS_TYPES = (pd.Series, pd.DataFrame, pd.Panel)\n"
     ]
    }
   ],
   "source": [
    "import intake\n",
    "import pprint\n",
    "import gcsfs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import datetime\n",
    "import cftime\n",
    "import pysolar\n",
    "from pysolar import *\n",
    "import dask\n",
    "import dask.delayed as delayed\n",
    "from dask import compute\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import cartopy\n",
    "#from tqdm.autonotebook import tqdm  # Fancy progress bars for our loops!\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = 12, 6\n",
    "%config InlineBackend.figure_format = 'retina' \n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "df = pd.read_csv('https://storage.googleapis.com/cmip6/cmip6-zarr-consolidated-stores.csv')\n",
    "fs = gcsfs.GCSFileSystem(token='anon', access='read_only')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Light calculations\n",
    "Here we use pysolar python modules to perform the light calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/trondkr/anaconda3/envs/py3/lib/python3.7/site-packages/pysolar/solartime.py:112: UserWarning: I don't know about leap seconds after 2018\n",
      "  (leap_seconds_base_year + len(leap_seconds_adjustments) - 1)\n"
     ]
    }
   ],
   "source": [
    "latitude_deg=37.77\n",
    "longitude_deg=-122.41\n",
    "latitudes=np.arange(0,90,1)\n",
    "\n",
    "d = datetime.datetime.now(datetime.timezone(offset=datetime.timedelta(hours=-8)))\n",
    "thirty_minutes = datetime.timedelta(hours = 2)\n",
    "for _ in range(48):\n",
    "    timestamp = d.ctime()\n",
    "    altitude_deg = solar.get_altitude(latitude_deg, longitude_deg, d)\n",
    "    azimuth_deg = solar.get_azimuth(latitude_deg, longitude_deg, d)\n",
    "    power = radiation.get_radiation_direct(d, altitude_deg)\n",
    "    \n",
    "    test3=pysolar.util.global_irradiance_clear(latitude_deg, longitude_deg, d)\n",
    "    \n",
    "    \n",
    "    #if (altitude_deg > 0):\n",
    "   # print(timestamp, \"PST: {:.2f} {:.2f} \".format(power,test3))\n",
    "    d = d + thirty_minutes     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_labels = ['gr'] \n",
    "\n",
    "member_ids = ['r1i1p1f1', 'r1i1p1f2', 'r1i1p1f3', 'r2i1p1f1', 'r2i1p1f2', 'r2i1p1f3', 'r3i1p1f1', 'r3i1p1f2', \n",
    "    'r4i1p1f1', 'r4i1p1f2', 'r4i1p1f3', 'r5i1p1f1', 'r5i1p1f2', 'r5i1p1f3', 'r6i1p1f1', 'r6i1p1f2', 'r6i1p1f3', 'r7i1p1f1', 'r7i1p1f2',\n",
    "    'r7i1p1f3', 'r8i1p1f1', 'r8i1p1f2', 'r8i1p1f3', 'r9i1p1f1', 'r9i1p1f2', 'r9i1p1f3', 'r102i1p1f1', 'r102i1p1f2', 'r102i1p1f3']\n",
    "member_ids = ['r1i1p1f1']\n",
    "\n",
    "experiment_ids = ['1pctCO2'] #'abrupt-4xCO2',\n",
    "institution_ids = [ 'NOAA-GFDL'] \n",
    "source_ids = ['GFDL-ESM4']\n",
    "variable_ids = [\"sithick\",\"siconc\",\"sisnthick\",\"sisnconc\"]\n",
    "table_ids=['SImon','SImon','SImon','SImon']\n",
    "#variable_ids = [\"sithick\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query data\n",
    "The dataset returned from the query need to be checked for time dimension. If the time array \n",
    "uses a relative date (0001 instead of 20001) then the values need to be added 2000 prior to converting to \n",
    "datetime64 format.\n",
    "\n",
    "https://unidata.github.io/cftime/api.html\n",
    "http://xarray.pydata.org/en/stable/time-series.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_timeseries(ds_dict,ds_area):\n",
    "\n",
    "    plt.figure(figsize=(12,8))\n",
    "\n",
    "    for name, ds in ds_dict.items():\n",
    "    \n",
    "      #  total_area = ds_area.areacella.sum(dim=['lat', 'lon'])\n",
    "     #   print(ds_area.areacella)\n",
    "        if name=='sithick':\n",
    "            ta_timeseries = ds.sithick.mean(dim=['lat','lon']) #* ds_area.areacella).sum(dim=['lon', 'lat']) / total_area\n",
    "        if name=='sisnthick':\n",
    "            ta_timeseries = ds.sisnthick.mean(dim=['lat','lon']) #* ds_area.areacella).sum(dim=['lon', 'lat']) / total_area\n",
    "        if name=='siconc':\n",
    "            ta_timeseries = ds.siconc.mean(dim=['lat','lon']) #* ds_area.areacella).sum(dim=['lon', 'lat']) / total_area\n",
    "        if name=='sisnconc':\n",
    "            ta_timeseries = ds.sisnconc.mean(dim=['lat','lon']) #* ds_area.areacella).sum(dim=['lon', 'lat']) / total_area\n",
    "        if name=='tas':\n",
    "            ta_timeseries = ds.tas.mean(dim=['lat','lon']) #* ds_area.areacella).sum(dim=['lon', 'lat']) / total_area\n",
    "         \n",
    "        plt.ylabel(r'global-mean {}'.format(name))\n",
    "        ta_timeseries.plot()\n",
    "        ta_timeseries.rolling(time=12).mean().plot(color='r')\n",
    "\n",
    "        plt.xlabel('time')\n",
    "     #   plt.xlim([1850,2100]);\n",
    "        plt.show()\n",
    "  #  plot_map(ds)\n",
    "    #plt.savefig('../figures/ssp585_global_warming.png',dpi=100,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_map(ds):\n",
    "    plt.figure(figsize=(14,6))\n",
    "    ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "    ax.set_global()\n",
    "    ds.sithick[0].plot.pcolormesh(ax=ax, transform=ccrs.PlateCarree(), x='xc', y='yc', add_colorbar=False)\n",
    "    ax.coastlines()\n",
    "    ax.set_ylim([0,90]);\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_query(query_string):\n",
    "    df_sub = df.query(query_string)\n",
    "    mapper = fs.get_mapper(df_sub.zstore.values[-1])\n",
    "    ds = xr.open_zarr(mapper, consolidated=True)\n",
    "    time_object=ds['time'].values[0]\n",
    "    \n",
    "    # Convert if necesssary\n",
    "    if (time_object.year==1):\n",
    "      \n",
    "        times=ds['time'].values\n",
    "        times_plus_2000=[]\n",
    "        for t in times:\n",
    "            times_plus_2000.append(cftime.DatetimeNoLeap(t.year+2000,t.month,t.day,t.hour))\n",
    "        ds['time'].values=times_plus_2000\n",
    "        ds = xr.decode_cf(ds)\n",
    "    print(\"=> Dates extracted range from {} to {}\\n\".format(ds['time'].values[0],ds['time'].values[-1])) \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/trondkr/anaconda3/envs/py3/lib/python3.7/site-packages/distributed/dashboard/core.py:72: UserWarning: \n",
      "Port 8787 is already in use. \n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the diagnostics dashboard on a random port instead.\n",
      "  warnings.warn(\"\\n\" + msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>inproc://192.168.1.235/6953/1</li>\n",
       "  <li><b>Dashboard: </b><a href='http://192.168.1.235/6953/1:49351/status' target='_blank'>http://192.168.1.235/6953/1:49351/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>1</li>\n",
       "  <li><b>Cores: </b>8</li>\n",
       "  <li><b>Memory: </b>17.18 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'inproc://192.168.1.235/6953/1' processes=1 threads=8, memory=17.18 GB>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask.distributed import Client, progress\n",
    "client = Client(processes=False) #threads_per_worker=2, n_workers=16)\n",
    "#client.cluster.scale(2)\n",
    "client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_light(lon,lat,when,snow_thickness,ice_thickness):\n",
    "    altitude_deg = solar.get_altitude(lat, lon, when)\n",
    "    surface_light = radiation.get_radiation_direct(when, altitude_deg)\n",
    "    \n",
    "    return calculate_light_under_sea_ice(snow_thickness,ice_thickness,surface_light)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateArea(lat0,lat1,lon0,lon1,areaIce):\n",
    "\n",
    "    earthRadius = 6371000\n",
    "    rad = np.pi / 180.0\n",
    "\n",
    "    \"\"\"    -180 <= lon0 < lon1 <= 180\n",
    "            -90 <= lat0 < lat1 <= 90\n",
    "            areaIce is in percent\n",
    "    \"\"\"\n",
    "\n",
    "    area = earthRadius**2 * (np.sin(lat1*rad)-np.sin(lat0*rad)) * (lon1 - lon0) * rad\n",
    "    return area * (areaIce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_light_under_sea_ice(snow_thickness,ice_thickness,surface_light,debug=False):\n",
    "    # Now calculate the amount of light below the sea ice and snow (Perovich 1996,\n",
    "    # but see  Jin 2006 Annals of Glaciology)\n",
    "    attenuationSnow = 20  #unit : m-1\n",
    "    attenuationIceTop10cm = 5\n",
    "    attenuationIceBelowSurface = 1\n",
    "    missing_value=1e20\n",
    "    \n",
    "    if 0 < snow_thickness  < missing_value:\n",
    "        albedo = 0.9\n",
    "        if debug is True:\n",
    "            print(\"Albedo for snow and ice covered water: {}\".format(albedo))\n",
    "        surface_light = (1.0 - albedo) * surface_light\n",
    "    if snow_thickness == 0 and 0 < ice_thickness < missing_value:\n",
    "        albedo = 0.5\n",
    "        if debug is True:\n",
    "            print(\"Albedo for ice covered water: {}\".format(albedo))\n",
    "        surface_light = (1.0 - albedo) * surface_light\n",
    "    if (snow_thickness == 0 and ice_thickness == 0) or (snow_thickness==missing_value and ice_thickness==missing_value):\n",
    "        albedo = 0.06\n",
    "        if debug is True:\n",
    "            print(\"Albedo for open water: {}\".format(albedo))\n",
    "        surface_light = (1.0 - albedo) * surface_light\n",
    "\n",
    "    Eb = surface_light\n",
    "    if debug is True:\n",
    "        print(\"\\nSurface light {}\".format(Eb))\n",
    "    if 0 < snow_thickness < missing_value:\n",
    "        Eb = surface_light * np.exp(attenuationSnow * (-snow_thickness))\n",
    "        if debug is True:\n",
    "            print(\"Eb with snow (%s m) : {}\".format(snow_thickness, Eb))\n",
    "\n",
    "    if  0.1 <= ice_thickness < missing_value:\n",
    "\n",
    "        Eb = Eb * np.exp(attenuationIceTop10cm * (-0.1))\n",
    "        if debug is True:\n",
    "            print(\"Eb with ice top (%s m) : {}\".format(ice_thickness, Eb))\n",
    "        Eb = Eb * np.exp(attenuationIceBelowSurface * (-(ice_thickness - 0.1)))\n",
    "        if debug is True:\n",
    "            print(\"Eb with ice below top (%s m) : {}\".format(ice_thickness - 0.1, Eb))\n",
    "    else:\n",
    "        Eb = Eb * np.exp(attenuationIceTop10cm * (-ice_thickness))\n",
    "        if debug is True:\n",
    "            print(\"Eb with ice top (%s m) : {}\".format(ice_thickness, Eb))\n",
    "\n",
    "    #print \"Eb\", Eb, \"snow\", snowthickness, \"ice\", icethickness, \"albedo\", albedo\n",
    "\n",
    "   # if snowthickness==missing_value or icethickness==missing_value or albedo==missing_value:\n",
    "   #     return missing_value\n",
    "    return Eb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tasks_for_dataset(dset_dict):\n",
    "    #client.cluster.scale(10)  # ask for ten 4-thread workers\n",
    "    \n",
    "    snow_thickness=dset_dict['sisnthick'].sisnthick\n",
    "    ice_thickness=dset_dict['sithick'].sithick\n",
    "   \n",
    "    dd=snow_thickness['time'].values[0]\n",
    "    when=datetime.datetime(dd.year,dd.month,dd.day,tzinfo=datetime.timezone.utc)\n",
    "\n",
    "    z=np.zeros((len(snow_thickness.lon.values),len(snow_thickness.lat.values)))\n",
    "    n, m = np.shape(z)\n",
    "    \n",
    "    zr = [delayed(calculate_light)(snow_thickness.lon[i],snow_thickness.lat[j],when,snow_thickness[0,j,i],ice_thickness[0,j,i]) for i in range(n) for j in range(m)]\n",
    "    final=dask.compute(zr)\n",
    "    \n",
    "    \n",
    "    zr=np.array(final).reshape((n,m))\n",
    "    print(np.shape(zr))\n",
    " #   ds = xr.DataArray(zr, dims=['lon', 'lat'],\n",
    "  #                         coords={'lon': x, #snow_thickness.lon,\n",
    "  #                                 'lat': y}) #snow_thickness.lat})\n",
    "#    ds.to_netcdf('test.nc')\n",
    "\n",
    "    \n",
    "    plt.figure(figsize=(12,12))\n",
    "    plt.imshow(zr)\n",
    "    plt.colorbar()\n",
    " \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful links\n",
    "https://climate-cms.org/2019/11/12/Calendars-and-monthly-data.html\n",
    "http://xarray.pydata.org/en/stable/examples/monthly-means.html\n",
    "https://rabernat.github.io/research_computing_2018/xarray-tips-and-tricks.html\n",
    "http://meteo.unican.es/work/xarray_seminar/xArray_seminar.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running historical query on data: \n",
      " ==> source_id=='GFDL-ESM4'and table_id=='SImon' and member_id=='r1i1p1f1' and grid_label=='gr' and experiment_id=='esm-hist' and variable_id=='sithick'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dicitionary to hold the queried variables\n",
    "dset_dict = {}\n",
    "first=True\n",
    "\n",
    "for experiment_id in experiment_ids:\n",
    "    for grid_label in grid_labels:\n",
    "        for source_id in source_ids:\n",
    "            for member_id in member_ids:\n",
    "                for variable_id,table_id in zip(variable_ids,table_ids):\n",
    "                    \n",
    "                    # Historical\n",
    "                    query_string=\"source_id=='{}'and table_id=='{}' and member_id=='{}' and grid_label=='{}' and experiment_id=='esm-hist' and variable_id=='{}'\".format(source_id,table_id,member_id,grid_label,variable_id)\n",
    "                    print(\"Running historical query on data: \\n ==> {}\\n\".format(query_string))\n",
    "                    ds_hist=perform_query(query_string)\n",
    "                    \n",
    "                    # Future projection depending on choice in experiment_id\n",
    "                    query_string=\"source_id=='{}'and table_id=='{}' and member_id=='{}' and grid_label=='{}' and experiment_id=='{}' and variable_id=='{}'\".format(source_id,table_id,member_id,grid_label,experiment_id,variable_id)\n",
    "                    print(\"Running projections query on data: \\n ==> {}\\n\".format(query_string))\n",
    "                    ds_proj=perform_query(query_string)\n",
    "                   \n",
    "                    if first:\n",
    "                        df_area = df.query(\"variable_id == 'areacella' and source_id =='{}'\".format(source_id))\n",
    "                        ds_area = xr.open_zarr(fs.get_mapper(df_area.zstore.values[0]), consolidated=True)\n",
    "                        first=False\n",
    "                    \n",
    "                    # Concatentate the historical and projections datasets\n",
    "                    ds = xr.concat([ds_hist, ds_proj],dim='time')\n",
    "                    \n",
    "                    # Remove the duplicate overlapping times (e.g. 2001-2014)\n",
    "                    _, index = np.unique(ds['time'], return_index=True)\n",
    "                    ds=ds.isel(time=index)\n",
    "                    \n",
    "                    # Save the dataset for variable_id in the dictionary\n",
    "                    dset_dict[variable_id]=ds\n",
    "                   \n",
    "    \n",
    "run_tasks_for_dataset(dset_dict)\n",
    "                \n",
    "# Plot the global average timeseries for each variable\n",
    "plot_timeseries(dset_dict,ds_area)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
